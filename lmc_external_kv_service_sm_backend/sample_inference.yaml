---
apiVersion: v1
kind: ConfigMap
metadata:
  name: lmcache-config-connector
  namespace: default
data:
  lmcache_config.yaml: |
    # Minimal LMCache config for external connector via RemoteBackend
    chunk_size: 512
    local_cpu: true
    max_local_cpu_size: 5
    remote_serde: naive
    remote_url: "external://host:0/lmc_external_kv_service_sm_backend.kv_service_sm_connector/?connector_name=KVServiceSMConnector"
    extra_config:
      kv_service_sm_url: "http://localhost:9200"
      kv_service_sm_shared_memory_name: "ai_toolkit_cache"
      kv_service_sm_bucket: "lmcache"
      kv_service_sm_lease_timeout_ms: 500
      kv_service_sm_lease_ttl_s: 30
      kv_service_sm_put_timeout_ms: 20000

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-connector
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-connector
  template:
    metadata:
      labels:
        app: vllm-connector
    spec:
      containers:
      - name: vllm
        image: lmcache/vllm-openai:latest
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "-lc"]
        args:
          - >-
            pip install --no-cache-dir aiohttp
            && pip install --no-cache-dir
            'git+https://github.com/lohitredddy/lmc_external_kv_service_sm_backend.git@latest'
            && /opt/venv/bin/vllm serve meta-llama/Llama-3.1-8B-Instruct
            --host 0.0.0.0 --port 8000
            --kv-transfer-config '{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'
        env:
        - name: LMCACHE_CONFIG_FILE
          value: "/lmcache-config/lmcache_config.yaml"
        ports:
        - containerPort: 8000
          name: http
        volumeMounts:
        - name: lmcache-config
          mountPath: /lmcache-config
      volumes:
      - name: lmcache-config
        configMap:
          name: lmcache-config-connector

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: lmcache-config-backend
  namespace: default
data:
  lmcache_config.yaml: |
    # Minimal LMCache config for external backend
    chunk_size: 512
    local_cpu: true
    max_local_cpu_size: 5
    # Do not set remote_url when using external backend directly
    external_backends: "KVServiceSM"
    extra_config:
      external_backend.KVServiceSM.module_path: lmc_external_kv_service_sm_backend.kv_service_sm_backend
      external_backend.KVServiceSM.class_name: KVServiceSMBackend
      # KVServiceSM settings (sample values)
      kv_service_sm_url: "http://localhost:9200"
      kv_service_sm_shared_memory_name: "ai_toolkit_cache"
      kv_service_sm_bucket: "lmcache"
      kv_service_sm_lease_timeout_ms: 500
      kv_service_sm_lease_ttl_s: 30
      kv_service_sm_put_timeout_ms: 20000

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-backend
  namespace: default
spec:
  replicas: 1
  selector:
    matchLabels:
      app: vllm-backend
  template:
    metadata:
      labels:
        app: vllm-backend
    spec:
      containers:
      - name: vllm
        image: lmcache/vllm-openai:latest
        imagePullPolicy: IfNotPresent
        command: ["/bin/sh", "-lc"]
        args:
          - >-
            pip install --no-cache-dir aiohttp
            && pip install --no-cache-dir
            'git+https://github.com/lohitredddy/lmc_external_kv_service_sm_backend.git@latest'
            && /opt/venv/bin/vllm serve meta-llama/Llama-3.1-8B-Instruct
            --host 0.0.0.0 --port 8000
            --kv-transfer-config '{"kv_connector":"LMCacheConnectorV1","kv_role":"kv_both"}'
        env:
        - name: LMCACHE_CONFIG_FILE
          value: "/lmcache-config/lmcache_config.yaml"
        ports:
        - containerPort: 8000
          name: http
        volumeMounts:
        - name: lmcache-config
          mountPath: /lmcache-config
      volumes:
      - name: lmcache-config
        configMap:
          name: lmcache-config-backend
